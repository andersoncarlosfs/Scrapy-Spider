{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WebDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = 'websites.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from urllib.parse import urlparse\n",
    "except ImportError:\n",
    "     from urlparse import urlparse\n",
    "import encodings        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy # https://scrapy.org/\n",
    "import html2text # http://alir3z4.github.io/html2text/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "charset = 'utf-8'\n",
    "allowed_domains = []\n",
    "start_urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allowed domains and start URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(websites) as i:        \n",
    "    for l in i:  \n",
    "        if not l.isspace():\n",
    "            parsed = urlparse(l.rstrip())\n",
    "            start_urls.append(parsed.geturl())\n",
    "            allowed_domains.append(parsed.netloc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderScraper (scrapy.Spider):\n",
    "    \n",
    "    name = 'vanves'\n",
    "    counter = counter\n",
    "    charset = charset\n",
    "    start_urls = start_urls\n",
    "    allowed_domains = allowed_domains\n",
    "\n",
    "    def parse(self, response):\n",
    "        data = response.body\n",
    "        for c in set(encodings.aliases.aliases.values()):\n",
    "            try:\n",
    "                data = html2text.html2text(response.body.decode(c))\n",
    "                break\n",
    "            except UnicodeDecodeError as u:\n",
    "                continue\n",
    "            except Exception as e: \n",
    "                print response           \n",
    "                print(type(e))   \n",
    "                print(e.args)\n",
    "                print(e)   \n",
    "        if SpiderScraper.name in data:\n",
    "            with open(str(SpiderScraper.counter) + '.txt', 'w') as f:            \n",
    "                f.write(data)\n",
    "                SpiderScraper.counter += 1\n",
    "        for link in scrapy.Selector(response).xpath('*//a/@href').extract():\n",
    "            yield response.follow(link, self.parse)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [BeautifulSoup Grab Visible Webpage Text](https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text)\n",
    "- [How can I render JavaScript HTML to HTML in python?](https://stackoverflow.com/questions/29404856/how-can-i-render-javascript-html-to-html-in-python)\n",
    "- [How to get html with javascript rendered sourcecode by using selenium](https://stackoverflow.com/questions/22739514/how-to-get-html-with-javascript-rendered-sourcecode-by-using-selenium)\n",
    "- [Rendered HTML to plain text using Python ](https://stackoverflow.com/questions/13337528/rendered-html-to-plain-text-using-python)\n",
    "- [Python - html2text write to file](https://stackoverflow.com/questions/28602868/python-html2text-write-to-file)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [Get protocol + host name from URL](https://stackoverflow.com/questions/9626535/get-protocol-host-name-from-url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
